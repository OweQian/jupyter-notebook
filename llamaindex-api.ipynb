{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LlamaIndex Api\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初始化\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初始化环境变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { config } from \"dotenv\";\n",
    "\n",
    "await config({ export: true });\n",
    "\n",
    "const apiKey = Deno.env.get(\"API_KEY\");\n",
    "const baseURL = Deno.env.get(\"BASE_URL\");\n",
    "const systemPrompt = Deno.env.get(\"SYSTEM_PROMPT\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初始化 ai 实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { OpenAI, OpenAIEmbedding } from 'llamaindex';\n",
    "\n",
    "const llm = new OpenAI({\n",
    "  apiKey: apiKey,\n",
    "  model: 'gpt-4o',\n",
    "  maxTokens: 4096,\n",
    "  additionalSessionOptions: {\n",
    "    baseURL: baseURL\n",
    "  },\n",
    "  temperature: 0.4,\n",
    "});\n",
    "\n",
    "const embedModel = new OpenAIEmbedding({\n",
    "  apiKey: apiKey,\n",
    "  model: 'text-embedding-ada-002',\n",
    "  additionalSessionOptions: {\n",
    "    baseURL: baseURL\n",
    "  }\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 通过 LlamaIndex 调用 AI Api\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const stream = await llm.chat({\n",
    "  messages: [\n",
    "    {\n",
    "      role: \"system\",\n",
    "      content: systemPrompt\n",
    "    },\n",
    "    {\n",
    "      role: \"user\",\n",
    "      content: \"生成一个登陆界面\"\n",
    "    }\n",
    "  ],\n",
    "  stream: true\n",
    "})\n",
    "\n",
    "let assistantContent = \"\";\n",
    "\n",
    "for await (const chunk of stream) {\n",
    "  console.log(chunk.delta);\n",
    "  assistantContent += chunk.delta;\n",
    "}\n",
    "\n",
    "console.log(assistantContent);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 快速构建一个RAG示例\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { \n",
    "  Document,\n",
    "  VectorStoreIndex,\n",
    "  serviceContextFromDefaults,\n",
    "  ContextChatEngine,\n",
    "  Settings,\n",
    "  CallbackManager\n",
    "} from 'llamaindex';\n",
    "\n",
    "// 创建一个文档\n",
    "const document = new Document({ \n",
    "  text: assistantContent,\n",
    "  id_: \"login-component-doc\"\n",
    "});\n",
    "\n",
    "const serviceContext = serviceContextFromDefaults({\n",
    "  embedModel,\n",
    "  chunkSize: 100,\n",
    "  chunkOverlap: 10\n",
    "});\n",
    "  \n",
    "// 创建一个向量存储索引\n",
    "const index = await VectorStoreIndex.fromDocuments([document], { serviceContext });\n",
    "\n",
    "// 创建一个检索器\n",
    "const retriever = index.asRetriever({\n",
    "  similarityTopK: 3\n",
    "});\n",
    "\n",
    "// 创建一个上下文聊天引擎\n",
    "const chatEngine = new ContextChatEngine({\n",
    "  retriever,\n",
    "  chatModel: llm,\n",
    "  systemPrompt: `根据知识回答用户的问题`\n",
    "});\n",
    "\n",
    "const createCallbackManager = () => {\n",
    "  const callbackManager = new CallbackManager();\n",
    "  // retrieve-end\n",
    "  callbackManager.on('retrieve-end', (data) => {\n",
    "    const { nodes } = data.detail;\n",
    "    console.log('nodes', nodes);\n",
    "    relevantContent = nodes.map((node) => ({\n",
    "    content: node.node.toJSON().text,\n",
    "    similarity: node.score || 0\n",
    "    }));\n",
    "  });\n",
    "  return callbackManager;\n",
    "};\n",
    "\n",
    "createCallbackManager();\n",
    "\n",
    "const chatFn = () => {\n",
    "  return chatEngine.chat({\n",
    "    message: \"用到了哪些antd组件\",\n",
    "    stream: true\n",
    "  });\n",
    "};\n",
    "\n",
    "Settings.withCallbackManager(createCallbackManager(), chatFn);\n",
    "\n",
    "const response = await chatFn()\n",
    "\n",
    "let responseContent = \"\";\n",
    "for await (const chunk of response) {\n",
    "  console.log(chunk?.delta);\n",
    "  responseContent += chunk?.delta;\n",
    "}\n",
    "\n",
    "console.log(responseContent);\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LlamaIndex 更多资料详见官方文档：https://ts.llamaindex.ai/docs/llamaindex"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
